{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vCjY6f-mbLg7BUnpzNG89X40cshVBsUY",
      "authorship_tag": "ABX9TyOVr16GccJONGHEAOkMUyCn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bphqk3/CF/blob/main/get_2122_game_stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2stzidJSok3"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Apr  9 17:48:08 2024\n",
        "\n",
        "@author: Brooke\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.wait import WebDriverWait\n",
        "from selenium.webdriver.support.ui import Select\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from io import StringIO\n",
        "\n",
        "chromedriver_path = Service(r'C:\\Users\\Brooke\\Desktop\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe')\n",
        "coptions = webdriver.ChromeOptions()\n",
        "coptions.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "coptions.add_argument(\"--enable-javascript\")\n",
        "coptions.add_argument(\"--window-size=1920,1080\")\n",
        "#coptions.add_argument('--headless')\n",
        "coptions.add_argument('log-level=3')\n",
        "coptions.add_argument('--disable-dev-shm-usage')\n",
        "coptions.add_argument(\"--no-sandbox\")\n",
        "coptions.add_argument(\"--disable-crash-reporter\")\n",
        "coptions.add_argument(\"--disable-extensions\")\n",
        "\n",
        "player_url_list = ['https://www.nba.com/stats/players/boxscores-traditional?Season=2021-22',\n",
        "                   'https://www.nba.com/stats/players/boxscores-advanced?Season=2021-22',\n",
        "                   'https://www.nba.com/stats/players/boxscores-misc?Season=2021-22',\n",
        "                   'https://www.nba.com/stats/players/boxscores-scoring?Season=2021-22',\n",
        "                   'https://www.nba.com/stats/players/boxscores-usage?Season=2021-22']\n",
        "\n",
        "team_url_list = ['https://www.nba.com/stats/teams/boxscores-traditional?Season=2021-22',\n",
        "                 'https://www.nba.com/stats/teams/boxscores-advanced?Season=2021-22',\n",
        "                 'https://www.nba.com/stats/teams/boxscores-scoring?Season=2021-22']\n",
        "\n",
        "for link in player_url_list:\n",
        "    url = link\n",
        "    driver = webdriver.Chrome(service=chromedriver_path,options=coptions)\n",
        "    driver.get(url)\n",
        "    WebDriverWait(driver,20).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[1]/div[2]/div[2]/div[3]/section[2]/div/div[2]/div[2]/div[1]/div[3]/div/label/div/select\")))\n",
        "    dropdown = Select(driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[2]/div[3]/section[2]/div/div[2]/div[2]/div[1]/div[3]/div/label/div/select\"))\n",
        "    time.sleep(5)\n",
        "    dropdown.select_by_visible_text('All')\n",
        "    WebDriverWait(driver,20).until(EC.presence_of_element_located((By.CLASS_NAME,\"Crom_table__p1iZz\")))\n",
        "    table_element = driver.find_element(By.CLASS_NAME, 'Crom_table__p1iZz')\n",
        "    table_html = table_element.get_attribute('outerHTML')\n",
        "    df = pd.read_html(StringIO(table_html))[0]\n",
        "\n",
        "    df['GAME DATE']=pd.to_datetime(df['GAME DATE'], format='%m/%d/%Y')\n",
        "    # Convert the date column to \"yyyy-mm-dd\" format\n",
        "    df['GAME DATE'] = df['GAME DATE'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
        "\n",
        "    unique_player = df['PLAYER'].unique().tolist()\n",
        "    unique_player = sorted(unique_player)\n",
        "    dff = pd.DataFrame(unique_player, columns=['PLAYER'])\n",
        "\n",
        "    def generate_player_short(name, player_short_counts):\n",
        "        name_parts = name.split(' ')\n",
        "        first_initial = name_parts[0][0] + '.'\n",
        "        player_short = first_initial + ' ' + ' '.join(name_parts[1:])\n",
        "        if player_short in player_short_counts:\n",
        "            player_short_counts[player_short] += 1\n",
        "            return f\"{player_short} {player_short_counts[player_short]}\"\n",
        "        else:\n",
        "            player_short_counts[player_short] = 1\n",
        "            return player_short\n",
        "    # Add PLAYER_SHORT column\n",
        "    player_short_counts = {}\n",
        "    dff['Name'] = dff['PLAYER'].apply(lambda x: generate_player_short(x, player_short_counts))\n",
        "\n",
        "    merged_df = pd.merge(dff,df,on='PLAYER',how='left')\n",
        "\n",
        "    merged_df= merged_df.rename(columns={'PLAYER': 'Player', 'TEAM':'Team','MATCH UP':'Matchup','GAME DATE': 'Date'})\n",
        "    merged_df['Pos']=[None] * len(df)\n",
        "    merged_df.sort_values(by=['Date'], inplace = True)\n",
        "    merged_df.reset_index(drop=True, inplace = True) #3/19/24\n",
        "    stripped_url = url.split('-')[1]\n",
        "    stripped_url = stripped_url.replace(\"?\", \"\").replace(\"=\", \"\")\n",
        "\n",
        "    # Specify the full path to save the combined DataFrame\n",
        "    output_directory = 'C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\'\n",
        "    output_file_path = output_directory + 'player_stat_history' + stripped_url + '.parquet'\n",
        "\n",
        "    # Save the combined DataFrame to the specified directory\n",
        "    merged_df.to_parquet(output_file_path)\n",
        "    driver.close()\n",
        "\n",
        "for link in team_url_list:\n",
        "    url = link\n",
        "    driver = webdriver.Chrome(service=chromedriver_path,options=coptions)\n",
        "    driver.get(url)\n",
        "    WebDriverWait(driver,20).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[1]/div[2]/div[2]/div[3]/section[2]/div/div[2]/div[2]/div[1]/div[3]/div/label/div/select\")))\n",
        "    dropdown = Select(driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[2]/div[3]/section[2]/div/div[2]/div[2]/div[1]/div[3]/div/label/div/select\"))\n",
        "    time.sleep(5)\n",
        "    dropdown.select_by_visible_text('All')\n",
        "    WebDriverWait(driver,20).until(EC.presence_of_element_located((By.CLASS_NAME,\"Crom_table__p1iZz\")))\n",
        "    table_element = driver.find_element(By.CLASS_NAME, 'Crom_table__p1iZz')\n",
        "    table_html = table_element.get_attribute('outerHTML')\n",
        "    df = pd.read_html(StringIO(table_html))[0]\n",
        "\n",
        "    if 'Game\\xa0Date' in df.columns:\n",
        "        # Rename the column to 'Game Date'\n",
        "        df.rename(columns={'Team':'TEAM','Match\\xa0Up':'MATCH UP','Game\\xa0Date': 'GAME DATE'}, inplace=True)\n",
        "\n",
        "    if 'Game Date' in df.columns:\n",
        "        # Rename the column to 'Game Date'\n",
        "        df.rename(columns={'Team':'TEAM','Match Up':'MATCH UP','Game Date': 'GAME DATE'}, inplace=True)\n",
        "\n",
        "    if 'Matchup' in df.columns:\n",
        "        # Rename the column to 'Game Date'\n",
        "        df.rename(columns={'Team':'TEAM','Matchup':'MATCH UP','Date': 'GAME DATE'}, inplace=True)\n",
        "\n",
        "    df['GAME DATE']=pd.to_datetime(df['GAME DATE'], format='%m/%d/%Y')\n",
        "    # Convert the date column to \"yyyy-mm-dd\" format\n",
        "    df['GAME DATE'] = df['GAME DATE'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
        "\n",
        "    df= df.rename(columns={'TEAM':'Team','MATCH UP':'Matchup','GAME DATE': 'Date'})\n",
        "    df.sort_values(by=['Date'], inplace = True)\n",
        "    df.reset_index(drop=True,inplace = True) #3/19/24\n",
        "    stripped_url = url.split('-')[1]\n",
        "    stripped_url = stripped_url.replace(\"?\", \"\").replace(\"=\", \"\")\n",
        "    # Specify the full path to save the combined DataFrame\n",
        "    output_directory = 'C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\'\n",
        "    output_file_path = output_directory + 'team_stat_history' + stripped_url + '.parquet'\n",
        "\n",
        "    # Save the combined DataFrame to the specified directory\n",
        "    df.to_parquet(output_file_path)\n",
        "    driver.close()\n",
        "\n",
        "#generate merged dataframe with all the stats you care about per PLAYER\n",
        "\n",
        "a = pd.read_parquet('C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\player_stat_historytraditionalSeason2021.parquet')\n",
        "a = a.drop(['STL','BLK','TOV','PF', '+/-'],axis=1)\n",
        "\n",
        "b = pd.read_parquet('C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\player_stat_historyadvancedSeason2021.parquet')\n",
        "b = b.drop(['W/L', 'MIN','AST/TO','OREB%', 'DREB%','REB%', 'TO\\xa0Ratio','Pos'],axis=1)\n",
        "\n",
        "merged_df = pd.merge(a,b, on=['Player', 'Name','Team','Matchup','Date'], how='inner')\n",
        "\n",
        "c = pd.read_parquet('C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\player_stat_historymiscSeason2021.parquet')\n",
        "c = c.drop(['W/L', 'MIN','Opp PTS\\xa0OFF\\xa0TO', 'Opp 2nd\\xa0PTS', 'Opp FBPs','Opp PITP', 'BLK','BLKA','PF','Pos'],axis=1)\n",
        "merged_df2 = pd.merge(merged_df,c, on=['Player', 'Name','Team','Matchup','Date'], how='inner')\n",
        "\n",
        "d = pd.read_parquet('C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\player_stat_historyscoringSeason2021.parquet')\n",
        "d = d.drop(['W/L', 'MIN','Pos'], axis=1)\n",
        "merged_df3 = pd.merge(merged_df2,d, on=['Player', 'Name','Team','Matchup','Date'], how='inner')\n",
        "\n",
        "e = pd.read_parquet('C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\player_stat_historyusageSeason2021.parquet')\n",
        "e = e.drop(['W/L', 'MIN','Pos','USG%','%STL', '%BLK', '%BLKA'], axis=1)\n",
        "merged_player_df = pd.merge(merged_df3,e, on=['Player', 'Name','Team','Matchup','Date'], how='inner')\n",
        "merged_player_df.insert(4,'Opponent',merged_player_df['Matchup'].str[-3:])\n",
        "\n",
        "f = pd.read_parquet('C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\team_stat_historytraditionalSeason2021.parquet')\n",
        "#team stats become opponent allowed, forced, commited stats\n",
        "f2 = f.drop(['W/L', 'MIN', 'STL', 'BLK', '+/-','Matchup', 'PTS', 'FGA', 'FG%', '3PA', 'FTA',\n",
        "       'FT%','3P%','OREB', 'DREB', 'REB', 'AST', 'TOV','FGM','3PM', 'FTM'],axis = 1)\n",
        "f2.rename(columns={'Team':'Opponent','PF':'Opp_Comitted_PF'}, inplace=True) #grab how many fouls team committed to add to row stat for opposing player\n",
        "f3 = f.drop(['W/L', 'MIN','STL', 'BLK', '+/-','PF'],axis = 1)\n",
        "f3.insert(0,'Opponent',f3['Matchup'].str[-3:])\n",
        "new_names = [(i,'Opp_Allowed_'+i) for i in f3.iloc[:, 4:].columns.values]\n",
        "f3.drop(['Team','Matchup'],axis=1,inplace = True)\n",
        "f3.rename(columns = dict(new_names), inplace=True)\n",
        "f3.rename(columns={'Opp_Allowed_TOV':'Opp_Forced_TOV'},inplace = True)\n",
        "f3['Opp_Allowed_2PM'] = f3['Opp_Allowed_FGM'] - f3['Opp_Allowed_3PM']\n",
        "f3['Opp_Allowed_2PA'] = f3['Opp_Allowed_FGA'] - f3['Opp_Allowed_3PA']\n",
        "mf = pd.merge(f2,f3, on=['Opponent', 'Date'])\n",
        "\n",
        "g = pd.read_parquet('C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\team_stat_historyadvancedSeason2021.parquet')\n",
        "g = g.drop(['W/L', 'MIN', 'OffRtg', 'DefRtg', 'NetRtg','AST%', 'AST/TO', 'AST Ratio', 'eFG%','TS%', 'PIE'],axis=1)\n",
        "g.insert(0,'Opponent',g['Matchup'].str[-3:])\n",
        "g.drop(['Team','Matchup'],axis=1,inplace = True)\n",
        "g.rename(columns={'OREB%':'Opp_Allowed_OREB%','DREB%':'Opp_Allowed_DREB%','REB%':'Opp_Allowed_REB%','TOV%':'Opp_Forced_TOV%','PACE':'Game Pace'},inplace = True)\n",
        "mf2 = pd.merge(mf,g, on=['Opponent', 'Date'])\n",
        "\n",
        "j = pd.read_parquet('C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\team_stat_historyscoringSeason2021.parquet')\n",
        "j = j.drop(['W/L', 'MIN'],axis=1)\n",
        "j.insert(0,'Opponent',j['Matchup'].str[-3:])\n",
        "new_names = [(i,'Opp_Allowed_'+i) for i in j.iloc[:, 4:].columns.values]\n",
        "j.drop(['Team','Matchup'],axis=1,inplace = True)\n",
        "j.rename(columns = dict(new_names), inplace=True)\n",
        "merged_opponent_team_df = pd.merge(mf2,j, on=['Opponent', 'Date'])\n",
        "\n",
        "merged_player_w_opp_team_df = pd.merge(merged_player_df,merged_opponent_team_df, on=['Opponent', 'Date'])\n",
        "\n",
        "#need to take non-percent team offensive stats to compute eventual player per 100 possessions stats\n",
        "#also good to have TEAM offensive stats; note this is always the same as the Opp_Allowed stat\n",
        "ff = pd.read_parquet('C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\team_stat_historytraditionalSeason2021.parquet')\n",
        "team = ff.copy()\n",
        "team = team.drop(['Matchup', 'W/L','MIN', 'FG%', '3P%', 'FT%', 'PF', '+/-'], axis = 1)\n",
        "new_names = [(i,'TEAM_'+i) for i in team.iloc[:, 2:].columns.values]\n",
        "team.rename(columns = dict(new_names), inplace=True)\n",
        "merged_player_w_teamPopp_team_df = pd.merge(merged_player_w_opp_team_df,team, on = ['Team', 'Date'], how = 'outer')\n",
        "\n",
        "#need to grab possession stats\n",
        "url = 'https://www.pbpstats.com/games/nba?Season=2021-22&SeasonType=Regular%2BSeason'\n",
        "driver = webdriver.Chrome(service=chromedriver_path,options=coptions)\n",
        "driver.get(url)\n",
        "WebDriverWait(driver,40).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div/div/main/div[3]/div/div/div[4]/div[1]/form/select\")))\n",
        "pgsel = Select(driver.find_element(By.XPATH,\"/html/body/div/div/main/div[3]/div/div/div[4]/div[1]/form/select\"))\n",
        "time.sleep(5)\n",
        "pgsel.select_by_visible_text('All')\n",
        "WebDriverWait(driver,40).until(EC.presence_of_element_located((By.CLASS_NAME,\"vgt-responsive\")))\n",
        "table_element = driver.find_element(By.CLASS_NAME, 'vgt-responsive')\n",
        "table_html = table_element.get_attribute('outerHTML')\n",
        "poss_df = pd.read_html(StringIO(table_html))[0]\n",
        "driver.close()\n",
        "#drop points cols\n",
        "poss_df = poss_df.drop(poss_df.columns[[3, 4]], axis=1)\n",
        "\n",
        "poss_df.rename(columns={poss_df.columns[0]: 'Date',\n",
        "                        poss_df.columns[1]: 'Home',\n",
        "                        poss_df.columns[2]: 'Away',\n",
        "                        poss_df.columns[3]: 'Home Possessions',\n",
        "                        poss_df.columns[4]:'Away Possessions' }, inplace = True)\n",
        "\n",
        "# Convert back to string in \"Y-M-D\" format\n",
        "poss_df['Date'] = poss_df['Date'].apply(lambda x: pd.to_datetime(x).strftime(\"%Y-%m-%d\"))\n",
        "df1 = poss_df.copy()\n",
        "df2 = poss_df.copy()\n",
        "df1['Team'] = df1.apply(lambda row: row['Away'], axis=1)\n",
        "df1['TEAM_Poss'] = df1.apply(lambda row: row['Away Possessions'], axis=1)\n",
        "df1['Opp_Poss'] = df1.apply(lambda row: row['Home Possessions'], axis=1)\n",
        "df2['Team'] = df1.apply(lambda row: row['Home'], axis=1)\n",
        "df2['TEAM_Poss'] = df2.apply(lambda row: row['Home Possessions'], axis=1)\n",
        "df2['Opp_Poss'] = df2.apply(lambda row: row['Away Possessions'], axis=1)\n",
        "poss_df = pd.concat([df1,df2],ignore_index=True)\n",
        "poss_df = poss_df.drop(['Home', 'Away', 'Home Possessions', 'Away Possessions'], axis = 1)\n",
        "merged_player_stats_wteam_wopp_team_df = pd.merge(merged_player_w_teamPopp_team_df,poss_df, on = ['Team', 'Date'], how = 'outer')\n",
        "merged_player_stats_wteam_wopp_team_df.sort_values(by=['Date','Name'], inplace = True)\n",
        "merged_player_stats_wteam_wopp_team_df.reset_index(drop=True,inplace = True)\n",
        "\n",
        "s = merged_player_stats_wteam_wopp_team_df\n",
        "\n",
        "output_directory = 'C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\nbacom\\\\game_history\\\\S2122\\\\'\n",
        "output_file_path = output_directory + 'raw_full_stats' + '.parquet'\n",
        "\n",
        "# Save the combined DataFrame to the specified directory\n",
        "s.to_parquet(output_file_path)\n",
        "\n",
        "\n",
        "\n",
        "s = pd.read_parquet('C:/Users/Brooke/Desktop/rbt/rbt_player_history/nbacom/game_history/S2122/raw_full_stats.parquet')\n",
        "#s['P+A'] = s['PTS'] + s['AST']\n",
        "#s['P+R'] = s['PTS'] + s['REB']\n",
        "#s['P+R+A'] = s['PTS'] + s['REB'] + s['AST']\n",
        "#s['R+A'] = s['REB'] + s['AST']\n",
        "\n",
        "s = s.drop(['OREB','DREB','REB','AST'],axis=1)\n",
        "\n",
        "s['Total_Game_Poss'] = s.groupby(\"Name\").apply(lambda x: x[\"Opp_Poss\"] + x[\"TEAM_Poss\"]).reset_index(level=0, drop=True)\n",
        "\n",
        "s['2PM'] = s.groupby(\"Name\").apply(lambda x: x['FGM'] - x['3PM']).reset_index(level=0, drop=True)\n",
        "s['2PA'] = s.groupby(\"Name\").apply(lambda x: x['FGA'] - x['3PA']).reset_index(level=0, drop=True)\n",
        "\n",
        "\n",
        "#totals need to be on a per player basis because players don't play every game\n",
        "#this means that true team totals would be the cumsum of the Team + unique(Date) columns\n",
        "ts = s[[\"Name\",\"Team\",\"Date\",\"TEAM_Poss\",\"TEAM_PTS\"]]\n",
        "ts['Total_TEAM_Poss'] = ts.groupby([\"Name\",\"Team\"], group_keys=False)['TEAM_Poss'].cumsum()\n",
        "ts['Total_TEAM_PTS'] = ts.groupby([\"Name\",\"Team\"], group_keys=False)['TEAM_PTS'].cumsum()\n",
        "\n",
        "s = pd.merge(s,ts,on=[\"Name\",\"Team\",\"Date\",\"TEAM_Poss\",\"TEAM_PTS\"],how='left')\n",
        "\n",
        "s['Total_PTS'] = s.groupby(\"Name\", group_keys=False)['PTS'].cumsum()\n",
        "s['Total_%TEAM_PTS'] = round((s['Total_PTS']/s['Total_TEAM_PTS'])*100,2)\n",
        "#s['Total_FGM'] = s.groupby(\"Name\", group_keys=False)['FGM'].cumsum()\n",
        "s = s.drop(['FGM'],axis=1)\n",
        "s['Total_FGA'] = s.groupby(\"Name\", group_keys=False)['FGA'].cumsum()\n",
        "\n",
        "s['Total_2PM'] = s.groupby(\"Name\", group_keys=False)['2PM'].cumsum()\n",
        "s['Total_2PA'] = s.groupby(\"Name\", group_keys=False)['2PA'].cumsum()\n",
        "s['Total_2P%'] = round((s['Total_2PM'] / s['Total_2PA'])*100,2)\n",
        "\n",
        "s['Total_3PM'] = s.groupby(\"Name\", group_keys=False)['3PM'].cumsum()\n",
        "s['Total_3PA'] = s.groupby(\"Name\", group_keys=False)['3PA'].cumsum()\n",
        "s['Total_3P%'] = round((s['Total_3PM'] / s['Total_3PA'])*100,2)\n",
        "\n",
        "s['Total_FTM'] = s.groupby(\"Name\", group_keys=False)['FTM'].cumsum()\n",
        "s['Total_FTA'] = s.groupby(\"Name\", group_keys=False)['FTA'].cumsum()\n",
        "s['Total_FT%'] = round((s['Total_FTM'] / s['Total_FTA'])*100,2)\n",
        "#Points/ [2*(Field Goals Attempted+0.44*Free Throws Attempted)]\n",
        "s['Total_TS%'] = round(s['Total_PTS'] / (2 * ((s['Total_FGA']) + (0.44 * s['Total_FTA'])))*100,2)\n",
        "#s['Total_OREB'] = s.groupby(\"Name\", group_keys=False)['OREB'].cumsum()\n",
        "#s['Total_DREB'] = s.groupby(\"Name\", group_keys=False)['DREB'].cumsum()\n",
        "#s['Total_REB'] = s.groupby(\"Name\", group_keys=False)['REB'].cumsum()\n",
        "\n",
        "\n",
        "#opponent stats should be true team stats against the player\n",
        "#TEAM_Poss = Opp_Allowed_Team_Poss\n",
        "os = s[[\"Opponent\",\"Date\",\"Opp_Poss\",\"TEAM_Poss\", \"Total_Game_Poss\",\"Opp_Allowed_PTS\",\"Opp_Allowed_FGA\",\n",
        "        \"Opp_Allowed_2PM\",\"Opp_Allowed_2PA\",\"Opp_Allowed_3PM\",\"Opp_Allowed_3PA\",\n",
        "        \"Opp_Allowed_FTM\",\"Opp_Allowed_FTA\",\"Opp_Allowed_REB\",\"Opp_Forced_TOV\"]]\n",
        "\n",
        "os.rename(columns={'TEAM_Poss':'Opp_Allowed_Team_Poss'},inplace=True)\n",
        "os = os.drop_duplicates()\n",
        "\n",
        "os['Total_Opp_Poss'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Poss'].cumsum()\n",
        "os['Total_Opp_Allowed_Team_Poss'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Allowed_Team_Poss'].cumsum()\n",
        "os['Total_Opp_Total_Game_Poss'] = os.groupby([\"Opponent\"], group_keys=False)['Total_Game_Poss'].cumsum()\n",
        "\n",
        "#os['Total_Opp_Comitted_PF'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Comitted_PF'].cumsum()\n",
        "os['Total_Opp_Allowed_PTS'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Allowed_PTS'].cumsum()\n",
        "os['Total_Opp_Allowed_FGA'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Allowed_FGA'].cumsum()\n",
        "\n",
        "os['Total_Opp_Allowed_2PM'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Allowed_2PM'].cumsum()\n",
        "os['Total_Opp_Allowed_2PA'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Allowed_2PA'].cumsum()\n",
        "os['Total_Opp_Allowed_2P%'] = round(os['Total_Opp_Allowed_2PM']/os['Total_Opp_Allowed_2PA']*100,2)\n",
        "\n",
        "os['Total_Opp_Allowed_3PM'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Allowed_3PM'].cumsum()\n",
        "os['Total_Opp_Allowed_3PA'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Allowed_3PA'].cumsum()\n",
        "os['Total_Opp_Allowed_3P%'] = round(os['Total_Opp_Allowed_3PM'] / os['Total_Opp_Allowed_3PA']*100,2)\n",
        "\n",
        "os['Total_Opp_Allowed_FTM'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Allowed_FTM'].cumsum()\n",
        "os['Total_Opp_Allowed_FTA'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Allowed_FTA'].cumsum()\n",
        "os['Total_Opp_Allowed_FT%'] = round(os['Total_Opp_Allowed_FTM']/os['Total_Opp_Allowed_FTA']*100,2)\n",
        "\n",
        "os['Total_Opp_Allowed_REB'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Allowed_REB'].cumsum()\n",
        "os['Total_Opp_Forced_TOV'] = os.groupby([\"Opponent\"], group_keys=False)['Opp_Forced_TOV'].cumsum()\n",
        "\n",
        "s = pd.merge(s,os,on=[\"Opponent\",\"Date\",\"Opp_Poss\", \"Total_Game_Poss\",\"Opp_Allowed_PTS\",\"Opp_Allowed_FGA\",\n",
        "        \"Opp_Allowed_2PM\",\"Opp_Allowed_2PA\",\"Opp_Allowed_3PM\",\"Opp_Allowed_3PA\",\n",
        "        \"Opp_Allowed_FTM\",\"Opp_Allowed_FTA\",\"Opp_Allowed_REB\",\"Opp_Forced_TOV\"],how='left')\n",
        "\n",
        "# this will allow me to take rolling stats with each day\n",
        "s['PTS_per100'] = round(s['Total_PTS']*100/s['Total_TEAM_Poss'],2)\n",
        "s['2PA_per100'] = round(s['Total_2PA']*100/s['Total_TEAM_Poss'],2)\n",
        "s['3PA_per100'] = round(s['Total_3PA']*100/s['Total_TEAM_Poss'],2)\n",
        "s['FTA_per100'] = round(s['Total_FTA']*100/s['Total_TEAM_Poss'],2)\n",
        "#s['PFD_per100'] = round(s['Total_PFD']*100/s['Total_TEAM_Poss'],2)\n",
        "\n",
        "#think on whether or not you want to take a differential of these stats as new columns?\n",
        "#currently think the rolling stats have this covered\n",
        "\n",
        "\n",
        "#s['OREB_per100'] = round(s['OREB']*100/s['TEAM_Poss'],2)\n",
        "#s['DREB_per100'] = round(s['DREB']*100/s['TEAM_Poss'],2)\n",
        "#s['REB_per100'] = round(s['REB']*100/s['TEAM_Poss'],2)\n",
        "#s['AST_per100'] =round(s['AST']*100/s['TEAM_Poss'],2)\n",
        "#s['PTS\\xa0OFF\\xa0TO_per100'] = round(s['PTS\\xa0OFF\\xa0TO']*100/s['TEAM_Poss'],2)\n",
        "#s['2nd\\xa0PTS_per100']= round(s['2nd\\xa0PTS']*100/s['TEAM_Poss'],2)\n",
        "#s['FBPs_per100'] = round(s['FBPs']*100/s['TEAM_Poss'],2)\n",
        "#s['PITP_per100']= round(s['PITP']*100/s['TEAM_Poss'],2)\n",
        "s = s.drop(['PTS\\xa0OFF\\xa0TO', '2nd\\xa0PTS', 'FBPs', 'PITP'],axis=1)\n",
        "\n",
        "#s['Opp_Comitted_PF_per100']= round(s['Total_Opp_Comitted_PF']*100/(s['Total_Opp_Total_Game_Poss']),2)\n",
        "s['Opp_Allowed_PTS_per100'] = round(s['Total_Opp_Allowed_PTS']*100/s['Total_Opp_Allowed_Team_Poss'],2)\n",
        "s['Opp_Allowed_2PA_per100'] = round(s['Total_Opp_Allowed_2PA']*100/s['Total_Opp_Allowed_Team_Poss'],2)\n",
        "s['Opp_Allowed_3PA_per100'] = round(s['Total_Opp_Allowed_3PA']*100/s['Total_Opp_Allowed_Team_Poss'],2)\n",
        "s['Opp_Allowed_FTA_per100'] = round(s['Total_Opp_Allowed_FTA']*100/s['Total_Opp_Allowed_Team_Poss'],2)\n",
        "#s['Opp_Allowed_OREB_per100'] = round(s['Opp_Allowed_OREB']*100/s['TEAM_Poss'],2)\n",
        "#s['Opp_Allowed_DREB_per100'] = round(s['Opp_Allowed_DREB']*100/s['TEAM_Poss'],2)\n",
        "s['Opp_Allowed_REB_per100'] = round(s['Total_Opp_Allowed_REB']*100/s['Total_Opp_Allowed_Team_Poss'],2)\n",
        "s['Opp_Forced_TOV_per100'] = round(s['Total_Opp_Forced_TOV']*100/s['Total_Opp_Allowed_Team_Poss'],2)\n",
        "\n",
        "\n",
        "s['Date'] = pd.to_datetime(s['Date'])\n",
        "s['Days_Rest'] = s.groupby(\"Name\",group_keys=False)['Date'].diff().dt.days\n",
        "s['Date']=s['Date'].dt.date\n",
        "columns_to_move1 = s.pop('Days_Rest')\n",
        "s.insert(loc=6, column='Days_Rest', value=columns_to_move1)\n",
        "s['Days_Rest'] = s['Days_Rest'].fillna(0)\n",
        "\n",
        "val1 = s.copy()\n",
        "\n",
        "# cols_avg = ['P+A', 'P+R','R+A',\n",
        "#             'P+R+A']\n",
        "\n",
        "\n",
        "#  ### This function changes each stat to be the median of the window_size num_games for each team,\n",
        "### and shifts it one so it does not include the current stats from box score\n",
        "\n",
        "\n",
        "player_med_cols = ['MIN', 'PTS_per100', '2PA_per100', 'Total_2P%', '3PA_per100', 'Total_3P%',\n",
        "            'FTA_per100', 'Total_FT%', 'Total_TS%', 'PACE', '%PTS 2PT',\n",
        "            '%PTS 3PT', '%PTS FT', 'Total_%TEAM_PTS']\n",
        "\n",
        "def transform_and_shift_gb_name(df, player_med_cols):\n",
        "    for column in player_med_cols:\n",
        "        for window_size in [1, 5, 10, 20]:\n",
        "            new_col_name = f'{column}_rolling_med{window_size}'\n",
        "            if window_size == 1:\n",
        "                rolling_med = df.groupby(\"Name\")[column].transform(lambda x: x.rolling(window=len(x), min_periods=window_size).median().round(2))\n",
        "            else:\n",
        "                rolling_med = df.groupby(\"Name\")[column].transform(lambda x: x.rolling(window=window_size, min_periods=window_size).median().round(2))\n",
        "            df[new_col_name] = rolling_med.groupby(df[\"Name\"]).shift(1)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the transformation and shifting within each group for each column in cols_med\n",
        "s = transform_and_shift_gb_name(s, player_med_cols)\n",
        "\n",
        "\n",
        "team_med_cols = [\"TEAM_Poss\",\"TEAM_PTS\"]\n",
        "\n",
        "ts2 = s[[\"Team\",\"Date\",\"TEAM_Poss\",\"TEAM_PTS\"]]\n",
        "ts2 = ts2.drop_duplicates()\n",
        "\n",
        "\n",
        "def transform_and_shift_gb_team(df, team_med_cols):\n",
        "    for column in team_med_cols:\n",
        "        for window_size in [1, 5, 10, 20]:\n",
        "            new_col_name = f'{column}_rolling_med{window_size}'\n",
        "            if window_size == 1:\n",
        "                rolling_med = df.groupby(\"Team\")[column].transform(lambda x: x.rolling(window=len(x), min_periods=window_size).median().round(2))\n",
        "            else:\n",
        "                rolling_med = df.groupby(\"Team\")[column].transform(lambda x: x.rolling(window=window_size, min_periods=window_size).median().round(2))\n",
        "            df[new_col_name] = rolling_med.groupby(df[\"Team\"]).shift(1)\n",
        "\n",
        "    return df\n",
        "\n",
        "ts2 = transform_and_shift_gb_team(ts2, team_med_cols)\n",
        "s = pd.merge(s,ts2,on=[\"Team\",\"Date\",\"TEAM_Poss\",\"TEAM_PTS\"],how='left')\n",
        "\n",
        "\n",
        "opp_med_cols = ['Opp_Poss','Opp_Allowed_Team_Poss','Opp_Allowed_PTS_per100','Opp_Allowed_2PA_per100',\n",
        "            'Opp_Allowed_3PA_per100','Opp_Allowed_FTA_per100','Opp_Allowed_REB_per100',\n",
        "            'Opp_Forced_TOV_per100','Total_Opp_Allowed_2P%','Total_Opp_Allowed_3P%',\n",
        "            'Total_Opp_Allowed_FT%','Game Pace']\n",
        "\n",
        "os2 = s[['Opponent','Date','Opp_Poss','Opp_Allowed_Team_Poss',\n",
        "         'Opp_Allowed_PTS_per100','Opp_Allowed_2PA_per100',\n",
        "            'Opp_Allowed_3PA_per100','Opp_Allowed_FTA_per100','Opp_Allowed_REB_per100',\n",
        "            'Opp_Forced_TOV_per100','Total_Opp_Allowed_2P%','Total_Opp_Allowed_3P%',\n",
        "            'Total_Opp_Allowed_FT%','Game Pace']]\n",
        "\n",
        "os2 = os2.drop_duplicates()\n",
        "\n",
        "def transform_and_shift_gb_opp(df, opp_med_cols):\n",
        "    for column in opp_med_cols:\n",
        "        for window_size in [1, 5, 10, 20]:\n",
        "            new_col_name = f'{column}_rolling_med{window_size}'\n",
        "            if window_size == 1:\n",
        "                rolling_med = df.groupby(\"Opponent\")[column].transform(lambda x: x.rolling(window=len(x), min_periods=window_size).median().round(2))\n",
        "            else:\n",
        "                rolling_med = df.groupby(\"Opponent\")[column].transform(lambda x: x.rolling(window=window_size, min_periods=window_size).median().round(2))\n",
        "            df[new_col_name] = rolling_med.groupby(df[\"Opponent\"]).shift(1)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "os2 = transform_and_shift_gb_opp(os2, opp_med_cols)\n",
        "s = pd.merge(s,os2,on=['Opponent','Date','Opp_Poss','Opp_Allowed_Team_Poss','Opp_Allowed_PTS_per100','Opp_Allowed_2PA_per100',\n",
        "            'Opp_Allowed_3PA_per100','Opp_Allowed_FTA_per100','Opp_Allowed_REB_per100',\n",
        "            'Opp_Forced_TOV_per100','Total_Opp_Allowed_2P%','Total_Opp_Allowed_3P%',\n",
        "            'Total_Opp_Allowed_FT%','Game Pace'],how='left')\n",
        "\n",
        "\n",
        "\n",
        "output_directory = 'C:\\\\Users\\\\Brooke\\\\Desktop\\\\rbt\\\\rbt_player_history\\\\S2122\\\\'\n",
        "output_file_path = output_directory + 'player_full_stat_history.parquet'\n",
        "s.to_parquet(output_file_path)\n"
      ]
    }
  ]
}